{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T14:07:29.578105Z",
     "iopub.status.busy": "2025-10-27T14:07:29.577856Z",
     "iopub.status.idle": "2025-10-27T14:08:32.775368Z",
     "shell.execute_reply": "2025-10-27T14:08:32.774308Z",
     "shell.execute_reply.started": "2025-10-27T14:07:29.578087Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-google-genai 3.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\n",
      "langchain-huggingface 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.1 which is incompatible.\n",
      "langchain-experimental 0.3.4 requires langchain-core<0.4.0,>=0.3.28, but you have langchain-core 1.0.1 which is incompatible.\n",
      "langchain-groq 0.3.8 requires langchain-core<1.0.0,>=0.3.75, but you have langchain-core 1.0.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit -q\n",
    "!pip install chromadb -q\n",
    "!pip install groq -q\n",
    "!pip install langchain -q\n",
    "!pip install langchain-groq -q\n",
    "!pip install langchain_community -q\n",
    "!pip install langchain_huggingface -q\n",
    "!pip install langchain-core -q\n",
    "!pip install sentence-transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T14:08:32.777008Z",
     "iopub.status.busy": "2025-10-27T14:08:32.776779Z",
     "iopub.status.idle": "2025-10-27T14:08:35.252882Z",
     "shell.execute_reply": "2025-10-27T14:08:35.251899Z",
     "shell.execute_reply.started": "2025-10-27T14:08:32.776987Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "changed 22 packages in 20s\n",
      "\n",
      "3 packages are looking for funding\n",
      "  run `npm fund` for details\n"
     ]
    }
   ],
   "source": [
    "!npm install -g localtunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T14:08:35.254429Z",
     "iopub.status.busy": "2025-10-27T14:08:35.254084Z",
     "iopub.status.idle": "2025-10-27T14:08:35.424706Z",
     "shell.execute_reply": "2025-10-27T14:08:35.423966Z",
     "shell.execute_reply.started": "2025-10-27T14:08:35.254405Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget -q -O - ipv4.icanhazip.com\n",
    "# Copy the ransom ip address \"35.229.63.7\" and paste in the ramdon url's (https://mighty-ends-wish.loca.lt) tunnel password adter clicking the ramdom url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T14:08:35.426739Z",
     "iopub.status.busy": "2025-10-27T14:08:35.426464Z",
     "iopub.status.idle": "2025-10-27T14:08:35.434512Z",
     "shell.execute_reply": "2025-10-27T14:08:35.433957Z",
     "shell.execute_reply.started": "2025-10-27T14:08:35.426719Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "## With Questions\n",
    "import streamlit as st\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "st.set_page_config(layout=\"wide\", page_title=\"Q&A App\", page_icon=\"ðŸ§ \")\n",
    "\n",
    "# Loading GROQ API Key\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "st.title(\"ðŸ§  Q&A App\")\n",
    "\n",
    "\n",
    "# Initializing the llama-3.3 LLM\n",
    "llm = ChatGroq(groq_api_key=groq_api_key,\n",
    "               model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "# Creating path for Vector Store\n",
    "path_vectorstore = \"vectorstore\"\n",
    "os.makedirs(path_vectorstore, exist_ok=True)\n",
    "\n",
    "# Defining the prompt\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a retrieval-augmented generation (RAG) assistant.\n",
    "\n",
    "    Use only the retrieved context to answer the question.\n",
    "    If unsure, output \"Not enough information.\"\n",
    "\n",
    "    Your Answer should be strictly valid JSON with this format:\n",
    "    {{\n",
    "    \"answer\": \"<string>\",\n",
    "    \"contexts\": [\"<string>\", \"<string>\", ...],\n",
    "    \"reasoning\": \"<string>\"\n",
    "    }}\n",
    "\n",
    "    CONTEXT:\n",
    "    {context}\n",
    "\n",
    "    QUESTION: {question}\n",
    "\n",
    "    YOUR ANSWER:\n",
    "\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Data preparation function\n",
    "def prepare_data():\n",
    "    data_path = \"D:\\AI-Job-Preparation\\Mini-RAG-System-Movie-Plots\\data\\wiki_movie_plots_deduped.csv\"\n",
    "    df=pd.read_csv(data_path, nrows = 200, usecols=[\"Title\",\"Plot\"])\n",
    "    \n",
    "    text_list = []\n",
    "    metadata = []\n",
    "    for _, row in df.iterrows():\n",
    "        text = 'Title: ' + row['Title'] + '\\n' + 'Plot: ' + row['Plot'] + '\\n'\n",
    "        text_list.append(text)\n",
    "        tags = row['Title']\n",
    "        metadata.append({'tags': tags, 'Title': row['Title']})\n",
    "    return text_list, metadata\n",
    "\n",
    "# Document creation function\n",
    "def create_doc():\n",
    "    text_list, metadata = prepare_data()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=20)\n",
    "    documents = text_splitter.create_documents(texts=text_list, metadatas=metadata)\n",
    "    return documents\n",
    "\n",
    "# Vector embedding function\n",
    "def vector_embedding():\n",
    "    if path_vectorstore not in st.session_state:\n",
    "        # Initializing embeddings\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_kwargs={'tokenizer_kwargs': {'clean_up_tokenization_spaces': True}}\n",
    "        )\n",
    "        \n",
    "        # Creating documents\n",
    "        documents = create_doc()\n",
    "        \n",
    "        # Creating vectorstore using LangChain's Chroma wrapper\n",
    "        vectorstore = Chroma.from_documents(\n",
    "            documents=documents,\n",
    "            embedding=embeddings,\n",
    "            persist_directory=path_vectorstore\n",
    "        )\n",
    "        \n",
    "        # Storing in session state\n",
    "        st.session_state[\"vectorstore\"] = vectorstore\n",
    "        st.write(\"Chroma Vector store initialized successfully.\")\n",
    "    else:\n",
    "        st.write(\"Chroma Vector store already initialized.\")\n",
    "\n",
    "# Taking Input from user\n",
    "user_prompt = st.text_input(\"Write Your Query\")\n",
    "\n",
    "# Button to prepare the vector store\n",
    "if st.button(\"Submit\"):\n",
    "    vector_embedding()\n",
    "    st.write(\"Chroma Vector Store is Ready\")\n",
    "\n",
    "# Handling retrieval and response\n",
    "if user_prompt:\n",
    "    if \"vectorstore\" not in st.session_state:\n",
    "        st.error(\"Chroma Vector store is not initialized. Please click 'Submit' to initialize it.\")\n",
    "    else:\n",
    "\n",
    "\n",
    "        retriever = st.session_state.vectorstore.as_retriever()\n",
    "        chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "        \n",
    "        start = time.process_time()\n",
    "        response = chain.invoke(user_prompt)\n",
    "        st.write(f\"Response Time: {time.process_time() - start:.2f} seconds\")\n",
    "        #st.code(response['answer'], language='markdown')\n",
    "        st.code(response, language='markdown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T14:08:35.435663Z",
     "iopub.status.busy": "2025-10-27T14:08:35.435221Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!streamlit run app.py & npx localtunnel --port 8501"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6525002,
     "sourceId": 10545883,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
